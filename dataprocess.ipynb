{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ALLERGIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed DataFrame (grouped by patient with allergy counts):\n",
      "                                PATIENT  Allergy to bee venom  \\\n",
      "0  00049ee8-5953-4edd-a277-b9c1b1a7f16b                     1   \n",
      "1  00093cdd-a9f0-4ad8-87e9-53534501f008                     0   \n",
      "2  001683f0-8546-4ac2-9153-dd1a9ffe29cd                     0   \n",
      "3  001890f9-3149-4347-ad12-739ad6db59cd                     0   \n",
      "4  001d5d6d-0818-4f61-8dfa-48dc1abe4c95                     0   \n",
      "\n",
      "   Allergy to grass pollen  Allergy to tree pollen  Allergy to fish  \\\n",
      "0                        0                       1                0   \n",
      "1                        1                       0                0   \n",
      "2                        0                       0                0   \n",
      "3                        0                       0                0   \n",
      "4                        0                       1                1   \n",
      "\n",
      "   Allergy to nut  Allergy to mould  Dander (animal) allergy  \\\n",
      "0               0                 1                        1   \n",
      "1               0                 1                        1   \n",
      "2               0                 0                        1   \n",
      "3               0                 0                        0   \n",
      "4               1                 1                        1   \n",
      "\n",
      "   Shellfish allergy  House dust mite allergy  Allergy to dairy product  \\\n",
      "0                  1                        0                         0   \n",
      "1                  0                        1                         0   \n",
      "2                  0                        0                         0   \n",
      "3                  1                        0                         0   \n",
      "4                  0                        1                         0   \n",
      "\n",
      "   Allergy to eggs  Allergy to wheat  Latex allergy  Allergy to soya  \\\n",
      "0                0                 0              0                0   \n",
      "1                1                 0              0                0   \n",
      "2                0                 0              0                0   \n",
      "3                0                 0              0                0   \n",
      "4                0                 0              1                0   \n",
      "\n",
      "   Allergy to peanuts  \n",
      "0                   0  \n",
      "1                   0  \n",
      "2                   0  \n",
      "3                   0  \n",
      "4                   0  \n",
      "Processed data has been saved to processed_allergies.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the allergies data from the CSV file\n",
    "file_path = '10k_synthea_covid19_csv/allergies.csv'  # Adjust the path if necessary\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# View the first few rows to understand the structure of the data\n",
    "# print(\"Original DataFrame:\")\n",
    "# print(df.head())\n",
    "\n",
    "# Ensure the DESCRIPTION column doesn't have leading/trailing spaces\n",
    "df['DESCRIPTION'] = df['DESCRIPTION'].str.strip()\n",
    "\n",
    "# Get unique allergy descriptions from the DESCRIPTION column\n",
    "unique_allergies = df['DESCRIPTION'].unique()\n",
    "\n",
    "# Create a count encoding for each unique allergy description\n",
    "for allergy in unique_allergies:\n",
    "    df[allergy] = df['DESCRIPTION'].apply(lambda x: 1 if x == allergy else 0)\n",
    "\n",
    "# Drop the 'DESCRIPTION' and other columns we don't need\n",
    "df = df.drop(columns=['DESCRIPTION', 'ENCOUNTER', 'START', 'STOP', 'CODE'])\n",
    "\n",
    "# Create a list of allergy columns (allergy columns are now binary columns)\n",
    "allergy_columns = [col for col in df.columns if col != 'PATIENT']\n",
    "\n",
    "# Now, group by the patient ID to consolidate the multiple encounters into one row per patient\n",
    "# Use 'sum' instead of 'max' to count the number of times each allergy appears\n",
    "df_patient = df.groupby('PATIENT')[allergy_columns].sum().reset_index()\n",
    "\n",
    "# View the processed DataFrame (grouped by patient)\n",
    "print(\"\\nProcessed DataFrame (grouped by patient with allergy counts):\")\n",
    "print(df_patient.head())\n",
    "\n",
    "# Save the resulting DataFrame to a new CSV file\n",
    "output_path = 'processed_allergies.csv'\n",
    "df_patient.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Processed data has been saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CarePlan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "                                     Id       START        STOP  \\\n",
      "0  fea43343-7312-423f-bb82-b2f5ae71a260  2020-03-01  2020-03-01   \n",
      "1  cbcade35-42bf-4807-8154-3f7f847221e0  2020-03-01  2020-03-30   \n",
      "2  51dd78df-2b01-486a-8b33-1fbcd9cec211  2020-02-12  2020-02-26   \n",
      "3  8aa5055b-cddc-4170-9e31-e71e5552502a  2020-03-13  2020-03-13   \n",
      "4  976d369a-2b71-488d-ba20-8674fc272be0  2020-03-13  2020-04-14   \n",
      "\n",
      "                                PATIENT                             ENCOUNTER  \\\n",
      "0  f0f3bc8d-ef38-49ce-a2bd-dfdda982b271  681c380b-3c84-4c55-80a6-db3d9ea12fee   \n",
      "1  f0f3bc8d-ef38-49ce-a2bd-dfdda982b271  681c380b-3c84-4c55-80a6-db3d9ea12fee   \n",
      "2  067318a4-db8f-447f-8b6e-f2f61e9baaa5  adedca64-700b-4fb9-82f1-9cbb658abb73   \n",
      "3  067318a4-db8f-447f-8b6e-f2f61e9baaa5  1ea74a77-3ad3-4948-a9cc-3084462035d6   \n",
      "4  067318a4-db8f-447f-8b6e-f2f61e9baaa5  1ea74a77-3ad3-4948-a9cc-3084462035d6   \n",
      "\n",
      "        CODE                                     DESCRIPTION   REASONCODE  \\\n",
      "0  736376001  Infectious disease care plan (record artifact)  840544004.0   \n",
      "1  736376001  Infectious disease care plan (record artifact)  840539006.0   \n",
      "2   91251008                      Physical therapy procedure   44465007.0   \n",
      "3  736376001  Infectious disease care plan (record artifact)  840544004.0   \n",
      "4  736376001  Infectious disease care plan (record artifact)  840539006.0   \n",
      "\n",
      "    REASONDESCRIPTION  \n",
      "0  Suspected COVID-19  \n",
      "1            COVID-19  \n",
      "2     Sprain of ankle  \n",
      "3  Suspected COVID-19  \n",
      "4            COVID-19  \n",
      "\n",
      "Processed DataFrame (grouped by patient and care plans only):\n",
      "                                PATIENT  \\\n",
      "0  0000b247-1def-417a-a783-41c8682be022   \n",
      "1  00049ee8-5953-4edd-a277-b9c1b1a7f16b   \n",
      "2  000769a6-23a7-426e-a264-cb0e509b2da2   \n",
      "3  00079a57-24a8-430f-b4f8-a1cf34f90060   \n",
      "4  0008a63c-c95c-46c2-9ef3-831d68892019   \n",
      "\n",
      "   Infectious disease care plan (record artifact)  Physical therapy procedure  \\\n",
      "0                                               2                           0   \n",
      "1                                               2                           0   \n",
      "2                                               0                           0   \n",
      "3                                               1                           0   \n",
      "4                                               1                           0   \n",
      "\n",
      "   Lifestyle education regarding hypertension  Diabetes self management plan  \\\n",
      "0                                           0                              0   \n",
      "1                                           0                              1   \n",
      "2                                           0                              0   \n",
      "3                                           1                              0   \n",
      "4                                           0                              0   \n",
      "\n",
      "   Fracture care  Routine antenatal care  Self-care interventions (procedure)  \\\n",
      "0              0                       0                                    0   \n",
      "1              0                       0                                    1   \n",
      "2              0                       0                                    0   \n",
      "3              0                       0                                    0   \n",
      "4              0                       0                                    0   \n",
      "\n",
      "   Chronic obstructive pulmonary disease clinical management plan  \\\n",
      "0                                                  0                \n",
      "1                                                  0                \n",
      "2                                                  0                \n",
      "3                                                  0                \n",
      "4                                                  0                \n",
      "\n",
      "   Asthma self management  ...  Bullet wound  Lupus erythematosus  \\\n",
      "0                       0  ...             0                    0   \n",
      "1                       0  ...             0                    0   \n",
      "2                       0  ...             0                    0   \n",
      "3                       0  ...             0                    0   \n",
      "4                       0  ...             0                    0   \n",
      "\n",
      "   Injury of anterior cruciate ligament  Third degree burn  \\\n",
      "0                                     0                  0   \n",
      "1                                     0                  0   \n",
      "2                                     0                  0   \n",
      "3                                     0                  0   \n",
      "4                                     0                  0   \n",
      "\n",
      "   Tear of meniscus of knee  Suicidal deliberate poisoning  \\\n",
      "0                         0                              0   \n",
      "1                         0                              0   \n",
      "2                         0                              0   \n",
      "3                         0                              0   \n",
      "4                         0                              0   \n",
      "\n",
      "   Attempted suicide - cut/stab  Cystic Fibrosis  \\\n",
      "0                             0                0   \n",
      "1                             0                0   \n",
      "2                             0                0   \n",
      "3                             0                0   \n",
      "4                             0                0   \n",
      "\n",
      "   Diabetes from Cystic Fibrosis  Male Infertility  \n",
      "0                              0                 0  \n",
      "1                              0                 0  \n",
      "2                              0                 0  \n",
      "3                              0                 0  \n",
      "4                              0                 0  \n",
      "\n",
      "[5 rows x 108 columns]\n",
      "Processed data has been saved to processed_careplans.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the care plans data from the CSV file\n",
    "file_path = '10k_synthea_covid19_csv/careplans.csv'  # Adjust the path if necessary\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# View the first few rows to understand the structure of the data\n",
    "print(\"Original DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Ensure the DESCRIPTION and REASONDESCRIPTION columns don't have leading/trailing spaces\n",
    "df['DESCRIPTION'] = df['DESCRIPTION'].str.strip()\n",
    "df['REASONDESCRIPTION'] = df['REASONDESCRIPTION'].str.strip()\n",
    "\n",
    "# Get unique care plan descriptions from the DESCRIPTION column\n",
    "unique_careplans = df['DESCRIPTION'].unique()\n",
    "\n",
    "# Get unique reason descriptions from the REASONDESCRIPTION column\n",
    "unique_reasons = df['REASONDESCRIPTION'].unique()\n",
    "\n",
    "# Create a count encoding for each unique care plan description\n",
    "for careplan in unique_careplans:\n",
    "    df[careplan] = df['DESCRIPTION'].apply(lambda x: 1 if x == careplan else 0)\n",
    "\n",
    "# Create a count encoding for each unique reason description\n",
    "for reason in unique_reasons:\n",
    "    df[reason] = df['REASONDESCRIPTION'].apply(lambda x: 1 if x == reason else 0)\n",
    "\n",
    "# Drop the unnecessary columns after encoding\n",
    "df = df.drop(columns=['Id', 'START', 'STOP', 'ENCOUNTER', 'CODE', 'DESCRIPTION', 'REASONCODE', 'REASONDESCRIPTION'])\n",
    "\n",
    "# Create a list of care plan columns (binary columns for both DESCRIPTION and REASONDESCRIPTION)\n",
    "careplan_columns = [col for col in df.columns if col != 'PATIENT']\n",
    "\n",
    "# Now, group by the patient ID to consolidate the multiple care plans into one row per patient\n",
    "# Apply 'sum' to count the occurrences of each care plan (we only keep 'PATIENT' and the care plan columns)\n",
    "df_patient = df.groupby('PATIENT')[careplan_columns].sum().reset_index()\n",
    "\n",
    "# View the processed DataFrame (patient + care plan count encoding)\n",
    "print(\"\\nProcessed DataFrame (grouped by patient and care plans only):\")\n",
    "print(df_patient.head())\n",
    "\n",
    "# Save the resulting DataFrame to a new CSV file\n",
    "output_path = 'processed_careplans.csv'\n",
    "df_patient.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Processed data has been saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "        START        STOP                               PATIENT  \\\n",
      "0  2019-02-15  2019-08-01  f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "1  2019-10-30  2020-01-30  f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "2  2020-03-01  2020-03-30  f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "3  2020-03-01  2020-03-01  f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "4  2020-03-01  2020-03-30  f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "\n",
      "                              ENCOUNTER       CODE         DESCRIPTION  \n",
      "0  d5ee30a9-362f-429e-a87a-ee38d999b0a5   65363002        Otitis media  \n",
      "1  8bca6d8a-ab80-4cbf-8abb-46654235f227   65363002        Otitis media  \n",
      "2  681c380b-3c84-4c55-80a6-db3d9ea12fee  386661006     Fever (finding)  \n",
      "3  681c380b-3c84-4c55-80a6-db3d9ea12fee  840544004  Suspected COVID-19  \n",
      "4  681c380b-3c84-4c55-80a6-db3d9ea12fee  840539006            COVID-19  \n",
      "\n",
      "Processed DataFrame (grouped by patient and conditions only):\n",
      "                                PATIENT  Otitis media  Fever (finding)  \\\n",
      "0  0000b247-1def-417a-a783-41c8682be022             0                1   \n",
      "1  00049ee8-5953-4edd-a277-b9c1b1a7f16b             0                1   \n",
      "2  000769a6-23a7-426e-a264-cb0e509b2da2             0                0   \n",
      "3  00079a57-24a8-430f-b4f8-a1cf34f90060             0                1   \n",
      "4  0008a63c-c95c-46c2-9ef3-831d68892019             0                1   \n",
      "\n",
      "   Suspected COVID-19  COVID-19  Sprain of ankle  Cough (finding)  \\\n",
      "0                   1         1                0                1   \n",
      "1                   1         1                0                1   \n",
      "2                   0         0                0                0   \n",
      "3                   1         1                0                1   \n",
      "4                   1         1                0                1   \n",
      "\n",
      "   Sputum finding (finding)  Diarrhea symptom (finding)  \\\n",
      "0                         1                           0   \n",
      "1                         0                           0   \n",
      "2                         0                           0   \n",
      "3                         0                           0   \n",
      "4                         0                           1   \n",
      "\n",
      "   Streptococcal sore throat (disorder)  ...  Tear of meniscus of knee  \\\n",
      "0                                     0  ...                         0   \n",
      "1                                     0  ...                         0   \n",
      "2                                     0  ...                         0   \n",
      "3                                     0  ...                         0   \n",
      "4                                     0  ...                         0   \n",
      "\n",
      "   Posttraumatic stress disorder  Female Infertility  Cystic Fibrosis  \\\n",
      "0                              0                   0                0   \n",
      "1                              0                   0                0   \n",
      "2                              0                   0                0   \n",
      "3                              0                   0                0   \n",
      "4                              0                   0                0   \n",
      "\n",
      "   Diabetes from Cystic Fibrosis  \\\n",
      "0                              0   \n",
      "1                              0   \n",
      "2                              0   \n",
      "3                              0   \n",
      "4                              0   \n",
      "\n",
      "   Blindness due to type 2 diabetes mellitus (disorder)  \\\n",
      "0                                                  0      \n",
      "1                                                  0      \n",
      "2                                                  0      \n",
      "3                                                  0      \n",
      "4                                                  0      \n",
      "\n",
      "   History of disarticulation at wrist (situation)  Male Infertility  \\\n",
      "0                                                0                 0   \n",
      "1                                                0                 0   \n",
      "2                                                0                 0   \n",
      "3                                                0                 0   \n",
      "4                                                0                 0   \n",
      "\n",
      "   Acute Cholecystitis  Cholelithiasis  \n",
      "0                    0               0  \n",
      "1                    0               0  \n",
      "2                    0               0  \n",
      "3                    0               0  \n",
      "4                    0               0  \n",
      "\n",
      "[5 rows x 181 columns]\n",
      "Processed data has been saved to processed_conditions.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the conditions data from the CSV file\n",
    "file_path = '10k_synthea_covid19_csv/conditions.csv'  # Adjust the path if necessary\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# View the first few rows to understand the structure of the data\n",
    "print(\"Original DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Ensure the DESCRIPTION column doesn't have leading/trailing spaces\n",
    "df['DESCRIPTION'] = df['DESCRIPTION'].str.strip()\n",
    "\n",
    "# Get unique condition descriptions from the DESCRIPTION column\n",
    "unique_conditions = df['DESCRIPTION'].unique()\n",
    "\n",
    "# Create a count encoding for each unique condition description\n",
    "for condition in unique_conditions:\n",
    "    df[condition] = df['DESCRIPTION'].apply(lambda x: 1 if x == condition else 0)\n",
    "\n",
    "# Drop the 'DESCRIPTION' and other unnecessary columns after encoding them\n",
    "df = df.drop(columns=['ENCOUNTER', 'START', 'STOP', 'CODE', 'DESCRIPTION'])\n",
    "\n",
    "# Create a list of condition columns (binary columns)\n",
    "condition_columns = [col for col in df.columns if col != 'PATIENT']\n",
    "\n",
    "# Now, group by the patient ID to consolidate the multiple conditions into one row per patient\n",
    "# Apply 'sum' to the condition columns to count the occurrences of each condition (instead of taking 'max')\n",
    "df_patient = df.groupby('PATIENT')[condition_columns].sum().reset_index()\n",
    "\n",
    "# View the processed DataFrame (patient + condition count encoding)\n",
    "print(\"\\nProcessed DataFrame (grouped by patient and conditions only):\")\n",
    "print(df_patient.head())\n",
    "\n",
    "# Save the resulting DataFrame to a new CSV file\n",
    "output_path = 'processed_conditions.csv'\n",
    "df_patient.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Processed data has been saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Immunizations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "         DATE                               PATIENT  \\\n",
      "0  2019-08-01  f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "1  2020-01-30  f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "2  2019-07-08  067318a4-db8f-447f-8b6e-f2f61e9baaa5   \n",
      "3  2019-10-15  ae9efba3-ddc4-43f9-a781-f72019388548   \n",
      "4  2020-02-21  199c586f-af16-4091-9998-ee4cfc02ee7a   \n",
      "\n",
      "                              ENCOUNTER  CODE  \\\n",
      "0  6a74fdef-2287-44bf-b9e7-18012376faca   140   \n",
      "1  821e57ac-9304-46a9-9f9b-83daf60e9e43    83   \n",
      "2  9aa748b8-3b44-4e34-b7a8-2e56f2ca3ca2   140   \n",
      "3  6f9b301a-2b06-4868-b968-4d24faac576b   140   \n",
      "4  5844b770-504a-4eb4-a655-8483881dafb1   140   \n",
      "\n",
      "                                         DESCRIPTION  BASE_COST  \n",
      "0  Influenza  seasonal  injectable  preservative ...     140.52  \n",
      "1                            Hep A  ped/adol  2 dose     140.52  \n",
      "2  Influenza  seasonal  injectable  preservative ...     140.52  \n",
      "3  Influenza  seasonal  injectable  preservative ...     140.52  \n",
      "4  Influenza  seasonal  injectable  preservative ...     140.52  \n",
      "\n",
      "Processed DataFrame (grouped by patient and immunizations only):\n",
      "                                PATIENT  \\\n",
      "0  0000b247-1def-417a-a783-41c8682be022   \n",
      "1  000769a6-23a7-426e-a264-cb0e509b2da2   \n",
      "2  00079a57-24a8-430f-b4f8-a1cf34f90060   \n",
      "3  00093cdd-a9f0-4ad8-87e9-53534501f008   \n",
      "4  000e7adf-cbaa-4fad-ab2f-658c32f7d4d3   \n",
      "\n",
      "   Influenza  seasonal  injectable  preservative free  \\\n",
      "0                                                  1    \n",
      "1                                                  1    \n",
      "2                                                  1    \n",
      "3                                                  1    \n",
      "4                                                  1    \n",
      "\n",
      "   Hep A  ped/adol  2 dose  meningococcal MCV4P  \\\n",
      "0                        0                    0   \n",
      "1                        0                    0   \n",
      "2                        0                    0   \n",
      "3                        0                    0   \n",
      "4                        0                    0   \n",
      "\n",
      "   Hep B  adolescent or pediatric  Hib (PRP-OMP)  rotavirus  monovalent  IPV  \\\n",
      "0                               0              0                      0    0   \n",
      "1                               0              0                      0    0   \n",
      "2                               0              0                      0    0   \n",
      "3                               0              0                      0    0   \n",
      "4                               0              0                      0    0   \n",
      "\n",
      "   DTaP  Pneumococcal conjugate PCV 13  Td (adult) preservative free  \\\n",
      "0     0                              0                             0   \n",
      "1     0                              0                             0   \n",
      "2     0                              0                             0   \n",
      "3     0                              0                             0   \n",
      "4     0                              0                             0   \n",
      "\n",
      "   Hep A  adult  varicella  MMR  zoster  HPV  quadrivalent  Hep B  adult  \\\n",
      "0             0          0    0       0                  1             0   \n",
      "1             0          0    0       0                  0             0   \n",
      "2             0          0    0       0                  0             0   \n",
      "3             0          0    0       0                  0             0   \n",
      "4             0          0    0       0                  0             0   \n",
      "\n",
      "   Tdap  pneumococcal polysaccharide vaccine  23 valent  \n",
      "0     0                                               0  \n",
      "1     0                                               0  \n",
      "2     0                                               0  \n",
      "3     0                                               1  \n",
      "4     0                                               0  \n",
      "Processed data has been saved to processed_immunizations.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the input and output file paths\n",
    "input_file_path = '10k_synthea_covid19_csv/immunizations.csv'  # Input file path\n",
    "output_file_path = 'processed_immunizations.csv'  # Output file path\n",
    "\n",
    "# Load the immunizations data from the CSV file\n",
    "df = pd.read_csv(input_file_path)\n",
    "\n",
    "# View the first few rows to understand the structure of the data\n",
    "print(\"Original DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Ensure the DESCRIPTION column doesn't have leading/trailing spaces\n",
    "df['DESCRIPTION'] = df['DESCRIPTION'].str.strip()\n",
    "\n",
    "# Get unique immunization descriptions from the DESCRIPTION column\n",
    "unique_immunizations = df['DESCRIPTION'].unique()\n",
    "\n",
    "# Create a count encoding for each unique immunization description\n",
    "for immunization in unique_immunizations:\n",
    "    df[immunization] = df['DESCRIPTION'].apply(lambda x: 1 if x == immunization else 0)\n",
    "\n",
    "# Drop the unnecessary columns after encoding them\n",
    "df = df.drop(columns=['ENCOUNTER', 'DATE', 'BASE_COST', 'CODE', 'DESCRIPTION'])\n",
    "\n",
    "# Create a list of immunization columns (binary columns)\n",
    "immunization_columns = [col for col in df.columns if col != 'PATIENT']\n",
    "\n",
    "# Now, group by the patient ID to consolidate the multiple immunizations into one row per patient\n",
    "# Apply 'sum' to the immunization columns to count the occurrences of each immunization (instead of using 'max')\n",
    "df_patient = df.groupby('PATIENT')[immunization_columns].sum().reset_index()\n",
    "\n",
    "# View the processed DataFrame (patient + immunization count encoding)\n",
    "print(\"\\nProcessed DataFrame (grouped by patient and immunizations only):\")\n",
    "print(df_patient.head())\n",
    "\n",
    "# Save the resulting DataFrame to a new CSV file\n",
    "df_patient.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Processed data has been saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Medications**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "        START        STOP                               PATIENT  \\\n",
      "0  2019-10-30  2019-11-13  f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "1  2019-10-30  2019-11-13  f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "2  2020-02-12  2020-02-26  067318a4-db8f-447f-8b6e-f2f61e9baaa5   \n",
      "3  2020-04-28  2020-05-08  067318a4-db8f-447f-8b6e-f2f61e9baaa5   \n",
      "4  2010-11-22  2011-08-30  ae9efba3-ddc4-43f9-a781-f72019388548   \n",
      "\n",
      "                                  PAYER                             ENCOUNTER  \\\n",
      "0  7c4411ce-02f1-39b5-b9ec-dfbea9ad3c1a  8bca6d8a-ab80-4cbf-8abb-46654235f227   \n",
      "1  7c4411ce-02f1-39b5-b9ec-dfbea9ad3c1a  8bca6d8a-ab80-4cbf-8abb-46654235f227   \n",
      "2  5059a55e-5d6e-34d1-b6cb-d83d16e57bcf  adedca64-700b-4fb9-82f1-9cbb658abb73   \n",
      "3  5059a55e-5d6e-34d1-b6cb-d83d16e57bcf  e03b96de-5604-4989-a2d5-03a63e041eab   \n",
      "4  d47b3510-2895-3b70-9897-342d681c769d  11a2dfae-53d4-4d13-a74b-c540a525a1c4   \n",
      "\n",
      "     CODE                                        DESCRIPTION  BASE_COST  \\\n",
      "0  308182                    Amoxicillin 250 MG Oral Capsule       7.05   \n",
      "1  313820               Acetaminophen 160 MG Chewable Tablet       5.72   \n",
      "2  313820               Acetaminophen 160 MG Chewable Tablet       5.25   \n",
      "3  834061          Penicillin V Potassium 250 MG Oral Tablet      13.90   \n",
      "4  999967  amLODIPine 5 MG / Hydrochlorothiazide 12.5 MG ...     263.49   \n",
      "\n",
      "   PAYER_COVERAGE  DISPENSES  TOTALCOST  REASONCODE  \\\n",
      "0             0.0          1       7.05         NaN   \n",
      "1             0.0          1       5.72         NaN   \n",
      "2             0.0          1       5.25         NaN   \n",
      "3             0.0          1      13.90  43878008.0   \n",
      "4             0.0          9    2371.41  59621000.0   \n",
      "\n",
      "                      REASONDESCRIPTION  \n",
      "0                                   NaN  \n",
      "1                                   NaN  \n",
      "2                                   NaN  \n",
      "3  Streptococcal sore throat (disorder)  \n",
      "4                          Hypertension  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
      "<ipython-input-51-b2beb2c250c8>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.98 GiB for an array with shape (2172, 431262) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-b2beb2c250c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmedication\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munique_medications\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# Filter out rows for the current medication\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mmedication_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DESCRIPTION'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmedication\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# Track dose occurrences for each patient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sagor\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3013\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3015\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3017\u001b[0m         \u001b[1;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sagor\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3068\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3069\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3070\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3072\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sagor\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3598\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3599\u001b[0m         \"\"\"\n\u001b[1;32m-> 3600\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3601\u001b[0m         \u001b[1;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3602\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sagor\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3582\u001b[0m         \u001b[0mnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3584\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3586\u001b[0m         new_data = self._mgr.take(\n",
      "\u001b[1;32mc:\\Users\\sagor\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5539\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5541\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5543\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sagor\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   5527\u001b[0m         \"\"\"\n\u001b[0;32m   5528\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5529\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5530\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5531\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sagor\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m   5537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5538\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5539\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5541\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sagor\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconsolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    986\u001b[0m         \u001b[0mbm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 988\u001b[1;33m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    989\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sagor\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    991\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 993\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    994\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sagor\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   1914\u001b[0m     \u001b[0mnew_blocks\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBlock\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1915\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1916\u001b[1;33m         merged_blocks = _merge_blocks(\n\u001b[0m\u001b[0;32m   1917\u001b[0m             \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcan_consolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\sagor\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   1940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1941\u001b[0m         \u001b[0margsort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1942\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1943\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 6.98 GiB for an array with shape (2172, 431262) and data type int64"
     ]
    }
   ],
   "source": [
    "# Define the input and output file paths\n",
    "input_file_path = '10k_synthea_covid19_csv/medications.csv'  # Input file path\n",
    "output_file_path = 'processed_medications.csv'  # Output file path\n",
    "\n",
    "# Load the medications data from the CSV file\n",
    "df = pd.read_csv(input_file_path)\n",
    "\n",
    "# View the first few rows to understand the structure of the data\n",
    "print(\"Original DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Ensure the DESCRIPTION and REASONDESCRIPTION columns don't have leading/trailing spaces\n",
    "df['DESCRIPTION'] = df['DESCRIPTION'].str.strip()\n",
    "df['REASONDESCRIPTION'] = df['REASONDESCRIPTION'].str.strip()\n",
    "\n",
    "# Get unique medication descriptions from the DESCRIPTION column\n",
    "unique_medications = df['DESCRIPTION'].unique()\n",
    "\n",
    "# Initialize a list to hold the new medication dose columns\n",
    "medication_columns = []\n",
    "\n",
    "# For each medication, we will create separate dose columns\n",
    "for medication in unique_medications:\n",
    "    # Filter out rows for the current medication\n",
    "    medication_df = df[df['DESCRIPTION'] == medication]\n",
    "    \n",
    "    # Track dose occurrences for each patient\n",
    "    medication_df['DOSE'] = medication_df.groupby('PATIENT').cumcount() + 1  # Counting doses\n",
    "    \n",
    "    # Create columns for each dose of the medication\n",
    "    for dose in medication_df['DOSE'].unique():\n",
    "        dose_column = f\"{medication}_Dose_{dose}\"  # Naming as Medication_1, Medication_2, etc.\n",
    "        \n",
    "        # Set DISPENSES for each dose, and 0 where no dose is recorded\n",
    "        df[dose_column] = 0  # Initialize with 0 (no dose)\n",
    "        df.loc[medication_df[medication_df['DOSE'] == dose].index, dose_column] = medication_df[medication_df['DOSE'] == dose]['DISPENSES'].values\n",
    "\n",
    "        # Add to the list of medication columns\n",
    "        medication_columns.append(dose_column)\n",
    "\n",
    "# Drop unnecessary columns after creating the new dose columns\n",
    "df = df.drop(columns=['PAYER', 'BASE_COST', 'PAYER_COVERAGE', 'DISPENSES', 'TOTALCOST', 'ENCOUNTER', 'START', 'STOP', 'CODE', 'DESCRIPTION', 'REASONCODE', 'REASONDESCRIPTION'])\n",
    "\n",
    "# Group by PATIENT and aggregate by summing the doses (if a patient has multiple doses, sum DISPENSES)\n",
    "df_patient = df.groupby('PATIENT')[medication_columns].sum().reset_index()\n",
    "\n",
    "# View the processed DataFrame (patient + medication doses)\n",
    "print(\"\\nProcessed DataFrame (grouped by patient and medications with doses):\")\n",
    "print(df_patient.head())\n",
    "\n",
    "# Save the resulting DataFrame to a new CSV file\n",
    "df_patient.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Processed data has been saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "         DATE                               PATIENT  \\\n",
      "0  2019-08-01  f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "1  2019-08-01  f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "2  2019-08-01  f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "3  2019-08-01  f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "4  2019-08-01  f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "\n",
      "                              ENCOUNTER     CODE  \\\n",
      "0  6a74fdef-2287-44bf-b9e7-18012376faca   8302-2   \n",
      "1  6a74fdef-2287-44bf-b9e7-18012376faca  72514-3   \n",
      "2  6a74fdef-2287-44bf-b9e7-18012376faca  29463-7   \n",
      "3  6a74fdef-2287-44bf-b9e7-18012376faca  77606-2   \n",
      "4  6a74fdef-2287-44bf-b9e7-18012376faca   9843-4   \n",
      "\n",
      "                                         DESCRIPTION VALUE    UNITS     TYPE  \n",
      "0                                        Body Height  82.7       cm  numeric  \n",
      "1  Pain severity - 0-10 verbal numeric rating [Sc...   2.0  {score}  numeric  \n",
      "2                                        Body Weight  12.6       kg  numeric  \n",
      "3                  Weight-for-length Per age and sex  86.1        %  numeric  \n",
      "4               Head Occipital-frontal circumference  46.9       cm  numeric  \n",
      "\n",
      "Duplicate entries (patient ID with the same DESCRIPTION):\n",
      "                                      PATIENT  \\\n",
      "0        f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "1        f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "2        f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "3        f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "4        f0f3bc8d-ef38-49ce-a2bd-dfdda982b271   \n",
      "...                                       ...   \n",
      "1659745  2712205f-755e-4897-acb3-926895b7d635   \n",
      "1659746  2712205f-755e-4897-acb3-926895b7d635   \n",
      "1659747  2712205f-755e-4897-acb3-926895b7d635   \n",
      "1659748  2712205f-755e-4897-acb3-926895b7d635   \n",
      "1659749  2712205f-755e-4897-acb3-926895b7d635   \n",
      "\n",
      "                                               DESCRIPTION  \n",
      "0                                              Body Height  \n",
      "1        Pain severity - 0-10 verbal numeric rating [Sc...  \n",
      "2                                              Body Weight  \n",
      "3                        Weight-for-length Per age and sex  \n",
      "4                     Head Occipital-frontal circumference  \n",
      "...                                                    ...  \n",
      "1659745                                               QALY  \n",
      "1659746                                               DALY  \n",
      "1659747                                               DALY  \n",
      "1659748                                               QOLS  \n",
      "1659749                                               QOLS  \n",
      "\n",
      "[1428586 rows x 2 columns]\n",
      "\n",
      "Processed DataFrame (grouped by patient and description values):\n",
      "                                     ALT (Elevated) AST (Elevated)  \\\n",
      "PATIENT                                                              \n",
      "0000b247-1def-417a-a783-41c8682be022              0              0   \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b              0              0   \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2              0              0   \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060              0              0   \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019              0              0   \n",
      "\n",
      "                                     Abuse Status [OMAHA]  \\\n",
      "PATIENT                                                     \n",
      "0000b247-1def-417a-a783-41c8682be022                    0   \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b                    0   \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2                    0   \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060                    0   \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019                    0   \n",
      "\n",
      "                                     Adenovirus A+B+C+D+E DNA [Presence] in Respiratory specimen by NAA with probe detection  \\\n",
      "PATIENT                                                                                                                        \n",
      "0000b247-1def-417a-a783-41c8682be022                         Negative (qualifier value)                                        \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b                                                  0                                        \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2                                                  0                                        \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060                         Negative (qualifier value)                                        \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019                         Negative (qualifier value)                                        \n",
      "\n",
      "                                     Alanine aminotransferase [Enzymatic activity/volume] in Serum or Plasma  \\\n",
      "PATIENT                                                                                                        \n",
      "0000b247-1def-417a-a783-41c8682be022                                                  0                        \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b                                                  0                        \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2                                                  0                        \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060                                               20.8                        \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019                                               37.2                        \n",
      "\n",
      "                                     Albumin  \\\n",
      "PATIENT                                        \n",
      "0000b247-1def-417a-a783-41c8682be022       0   \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b       0   \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2       0   \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060       0   \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019       0   \n",
      "\n",
      "                                     Albumin [Mass/volume] in Serum or Plasma  \\\n",
      "PATIENT                                                                         \n",
      "0000b247-1def-417a-a783-41c8682be022                                        0   \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b                                        0   \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2                                        0   \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060                                      3.9   \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019                                      4.2   \n",
      "\n",
      "                                     Alkaline Phosphatase  \\\n",
      "PATIENT                                                     \n",
      "0000b247-1def-417a-a783-41c8682be022                    0   \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b                    0   \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2                    0   \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060                    0   \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019                    0   \n",
      "\n",
      "                                     Alkaline phosphatase [Enzymatic activity/volume] in Serum or Plasma  \\\n",
      "PATIENT                                                                                                    \n",
      "0000b247-1def-417a-a783-41c8682be022                                                  0                    \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b                                                  0                    \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2                                                  0                    \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060                                               89.7                    \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019                                               70.0                    \n",
      "\n",
      "                                     American house dust mite IgE Ab in Serum  \\\n",
      "PATIENT                                                                         \n",
      "0000b247-1def-417a-a783-41c8682be022                                        0   \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b                                        0   \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2                                        0   \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060                                        0   \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019                                        0   \n",
      "\n",
      "                                      ...  \\\n",
      "PATIENT                               ...   \n",
      "0000b247-1def-417a-a783-41c8682be022  ...   \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b  ...   \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2  ...   \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060  ...   \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019  ...   \n",
      "\n",
      "                                     VR-12 Vitality (VT) score - oblique method  \\\n",
      "PATIENT                                                                           \n",
      "0000b247-1def-417a-a783-41c8682be022                                          0   \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b                                          0   \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2                                          0   \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060                                          0   \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019                                          0   \n",
      "\n",
      "                                     WBC Auto (Bld) [#/Vol]  \\\n",
      "PATIENT                                                       \n",
      "0000b247-1def-417a-a783-41c8682be022                      0   \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b                      0   \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2                      0   \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060                      0   \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019                      0   \n",
      "\n",
      "                                     Walnut IgE Ab in Serum  \\\n",
      "PATIENT                                                       \n",
      "0000b247-1def-417a-a783-41c8682be022                      0   \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b                      0   \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2                      0   \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060                      0   \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019                      0   \n",
      "\n",
      "                                     Weight difference [Mass difference] --pre dialysis - post dialysis  \\\n",
      "PATIENT                                                                                                   \n",
      "0000b247-1def-417a-a783-41c8682be022                                                  0                   \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b                                                  0                   \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2                                                  0                   \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060                                                  0                   \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019                                                  0                   \n",
      "\n",
      "                                     Weight-for-length Per age and sex  \\\n",
      "PATIENT                                                                  \n",
      "0000b247-1def-417a-a783-41c8682be022                                 0   \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b                                 0   \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2                                 0   \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060                                 0   \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019                                 0   \n",
      "\n",
      "                                     Wheat IgE Ab in Serum  \\\n",
      "PATIENT                                                      \n",
      "0000b247-1def-417a-a783-41c8682be022                     0   \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b                     0   \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2                     0   \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060                     0   \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019                     0   \n",
      "\n",
      "                                     White Blood Cell (Elevated)  \\\n",
      "PATIENT                                                            \n",
      "0000b247-1def-417a-a783-41c8682be022                           0   \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b                           0   \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2                           0   \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060                           0   \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019                           0   \n",
      "\n",
      "                                     White oak IgE Ab in Serum  \\\n",
      "PATIENT                                                          \n",
      "0000b247-1def-417a-a783-41c8682be022                         0   \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b                         0   \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2                         0   \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060                         0   \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019                         0   \n",
      "\n",
      "                                     pH of Arterial blood  \\\n",
      "PATIENT                                                     \n",
      "0000b247-1def-417a-a783-41c8682be022                    0   \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b                    0   \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2                    0   \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060                    0   \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019                  7.1   \n",
      "\n",
      "                                     pH of Urine by Test strip  \n",
      "PATIENT                                                         \n",
      "0000b247-1def-417a-a783-41c8682be022                         0  \n",
      "00049ee8-5953-4edd-a277-b9c1b1a7f16b                         0  \n",
      "000769a6-23a7-426e-a264-cb0e509b2da2                         0  \n",
      "00079a57-24a8-430f-b4f8-a1cf34f90060                         0  \n",
      "0008a63c-c95c-46c2-9ef3-831d68892019                         0  \n",
      "\n",
      "[5 rows x 201 columns]\n",
      "\n",
      "'UNIT' column not found. Available columns are:\n",
      "Index(['DATE', 'PATIENT', 'ENCOUNTER', 'CODE', 'DESCRIPTION', 'VALUE', 'UNITS',\n",
      "       'TYPE'],\n",
      "      dtype='object')\n",
      "No 'UNIT' column found, so legend table is not created.\n",
      "Processed data has been saved to processed_observations.csv\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the input and output file paths\n",
    "input_file_path = '10k_synthea_covid19_csv/observations.csv'  # Input file path\n",
    "output_file_path = 'processed_observations.csv'  # Output file path\n",
    "\n",
    "# Load the observations data from the CSV file\n",
    "df = pd.read_csv(input_file_path)\n",
    "\n",
    "# View the first few rows to understand the structure of the data\n",
    "print(\"Original DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Ensure the DESCRIPTION column doesn't have leading/trailing spaces\n",
    "df['DESCRIPTION'] = df['DESCRIPTION'].str.strip()\n",
    "\n",
    "# Handle duplicates: Check if any patient has the same DESCRIPTION more than once\n",
    "duplicates = df[df.duplicated(subset=['PATIENT', 'DESCRIPTION'], keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(\"\\nDuplicate entries (patient ID with the same DESCRIPTION):\")\n",
    "    print(duplicates[['PATIENT', 'DESCRIPTION']])\n",
    "\n",
    "# Create a pivot table where each row is a unique patient, and columns are the descriptions\n",
    "pivot_df = df.pivot_table(index='PATIENT', columns='DESCRIPTION', values='VALUE', aggfunc='first')\n",
    "\n",
    "# Replace NaN values with 0 (for missing descriptions for a patient)\n",
    "pivot_df = pivot_df.fillna(0)\n",
    "\n",
    "# Flatten the columns to remove multi-index from pivot table (if any)\n",
    "pivot_df.columns = [col for col in pivot_df.columns]\n",
    "\n",
    "# Save the resulting DataFrame to a new CSV file\n",
    "pivot_df.to_csv(output_file_path, index=True)\n",
    "\n",
    "# Print out the processed DataFrame\n",
    "print(\"\\nProcessed DataFrame (grouped by patient and description values):\")\n",
    "print(pivot_df.head())\n",
    "\n",
    "# Create a legend table for descriptions and units\n",
    "# Ensure that the UNIT column exists before creating the legend table\n",
    "if 'UNIT' in df.columns:\n",
    "    legend_df = df[['DESCRIPTION', 'UNIT']].drop_duplicates()\n",
    "else:\n",
    "    print(\"\\n'UNIT' column not found. Available columns are:\")\n",
    "    print(df.columns)\n",
    "\n",
    "# Save the legend table to a new CSV file\n",
    "legend_output_file_path = 'legend_table.csv'\n",
    "if 'UNIT' in df.columns:\n",
    "    legend_df.to_csv(legend_output_file_path, index=False)\n",
    "    print(f\"\\nLegend table has been saved to {legend_output_file_path}\")\n",
    "else:\n",
    "    print(\"No 'UNIT' column found, so legend table is not created.\")\n",
    "\n",
    "print(f\"Processed data has been saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# Define chunk size\n",
    "chunk_size = 100000  # Adjust based on memory\n",
    "\n",
    "# Function to clean columns and rename\n",
    "def clean_columns(df, prefix):\n",
    "    df.columns = df.columns.str.strip()  # Strip column names of leading/trailing spaces\n",
    "    if 'PATIENT' not in df.columns:\n",
    "        raise ValueError(f\"PATIENT column missing in {prefix} dataframe\")\n",
    "    df = df.rename(columns=lambda x: f\"{prefix}_{x}\" if x != \"PATIENT\" else x)\n",
    "    return df\n",
    "\n",
    "# Initialize an empty Dask dataframe for merging\n",
    "merged_df = dd.from_pandas(pd.DataFrame(), npartitions=1)\n",
    "\n",
    "# Function to filter and merge data for a single patient\n",
    "def merge_patient_data(file_path, prefix, patient_id):\n",
    "    chunk_list = []\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "        # Clean and filter for the specific patient ID\n",
    "        chunk = clean_columns(chunk, prefix)\n",
    "        chunk = chunk[chunk['PATIENT'] == patient_id]  # Filter for the patient\n",
    "        chunk_dd = dd.from_pandas(chunk, npartitions=4)\n",
    "        chunk_list.append(chunk_dd)\n",
    "    \n",
    "    # Concatenate all chunks for the given patient\n",
    "    patient_df = dd.concat(chunk_list, axis=0, interleave_partitions=True)\n",
    "    return patient_df\n",
    "\n",
    "# Specify the patient ID you want to process\n",
    "patient_id_to_process = 'df6b563d-1ff4-4833-9af8-84431e641e9c'  # Example patient ID\n",
    "\n",
    "# Process the allergies dataset\n",
    "allergies_df = merge_patient_data('10k_synthea_covid19_csv/allergies.csv', 'allergies', patient_id_to_process)\n",
    "\n",
    "# Process other datasets (you can adjust the file paths as needed)\n",
    "careplans_df = merge_patient_data('10k_synthea_covid19_csv/careplans.csv', 'careplans', patient_id_to_process)\n",
    "merged_df = dd.merge(allergies_df, careplans_df, on=\"PATIENT\", how=\"outer\")\n",
    "\n",
    "conditions_df = merge_patient_data('10k_synthea_covid19_csv/conditions.csv', 'conditions', patient_id_to_process)\n",
    "merged_df = dd.merge(merged_df, conditions_df, on=\"PATIENT\", how=\"outer\")\n",
    "\n",
    "immunizations_df = merge_patient_data('10k_synthea_covid19_csv/immunizations.csv', 'immunizations', patient_id_to_process)\n",
    "merged_df = dd.merge(merged_df, immunizations_df, on=\"PATIENT\", how=\"outer\")\n",
    "\n",
    "medications_df = merge_patient_data('10k_synthea_covid19_csv/medications.csv', 'medications', patient_id_to_process)\n",
    "merged_df = dd.merge(merged_df, medications_df, on=\"PATIENT\", how=\"outer\")\n",
    "\n",
    "# Optional: observations dataset, if needed\n",
    "observations_df = merge_patient_data('10k_synthea_covid19_csv/observations.csv', 'observations', patient_id_to_process)\n",
    "merged_df = dd.merge(merged_df, observations_df, on=\"PATIENT\", how=\"outer\")\n",
    "\n",
    "# Repartition the merged data for better memory handling\n",
    "merged_df = merged_df.repartition(npartitions=10)\n",
    "\n",
    "# Define output path\n",
    "output_path = 'E:/Downloads/merged_patient_data.h5'\n",
    "\n",
    "# Save to HDF5 format, ensuring it's a single file by using HDFStore\n",
    "with ProgressBar():\n",
    "    # Use pandas HDFStore to save to a single HDF5 file\n",
    "    with pd.HDFStore(output_path, mode='w') as store:\n",
    "        store.put('df', merged_df.compute(), index=False)\n",
    "\n",
    "# If you want to monitor the progress or print the first few rows, compute the head\n",
    "merged_df_computed = merged_df.head()\n",
    "print(merged_df_computed)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' import pandas as pd\\nimport dask.dataframe as dd\\n\\n\\nconditions_df = pd.read_csv(\\'10k_synthea_covid19_csv/conditions.csv\\')\\nimmunizations_df = pd.read_csv(\\'10k_synthea_covid19_csv/immunizations.csv\\')\\nmedications_df = pd.read_csv(\\'10k_synthea_covid19_csv/medications.csv\\')\\nobservations_df = pd.read_csv(\\'10k_synthea_covid19_csv/observations.csv\\')\\npatients_df = pd.read_csv(\\'10k_synthea_covid19_csv/patients.csv\\')\\nallergies_df = pd.read_csv(r\"10k_synthea_covid19_csv/allergies.csv\")\\ncareplans_df = pd.read_csv(\\'10k_synthea_covid19_csv/careplans.csv\\')\\n\\n# Display the first few rows of each dataframe to understand their structure\\n{\\n    \"allergies\": allergies_df.head(),\\n    \"careplans\": careplans_df.head(),\\n    \"conditions\": conditions_df.head(),\\n    \"immunizations\": immunizations_df.head(),\\n    \"medications\": medications_df.head(),\\n    \"observations\": observations_df.head(),\\n    \"patients\": patients_df.head()\\n}\\n '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "conditions_df = pd.read_csv('10k_synthea_covid19_csv/conditions.csv')\n",
    "immunizations_df = pd.read_csv('10k_synthea_covid19_csv/immunizations.csv')\n",
    "medications_df = pd.read_csv('10k_synthea_covid19_csv/medications.csv')\n",
    "observations_df = pd.read_csv('10k_synthea_covid19_csv/observations.csv')\n",
    "patients_df = pd.read_csv('10k_synthea_covid19_csv/patients.csv')\n",
    "allergies_df = pd.read_csv(r\"10k_synthea_covid19_csv/allergies.csv\")\n",
    "careplans_df = pd.read_csv('10k_synthea_covid19_csv/careplans.csv')\n",
    "\n",
    "# Display the first few rows of each dataframe to understand their structure\n",
    "{\n",
    "    \"allergies\": allergies_df.head(),\n",
    "    \"careplans\": careplans_df.head(),\n",
    "    \"conditions\": conditions_df.head(),\n",
    "    \"immunizations\": immunizations_df.head(),\n",
    "    \"medications\": medications_df.head(),\n",
    "    \"observations\": observations_df.head(),\n",
    "    \"patients\": patients_df.head()\n",
    "}\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Rename columns with Dask for proper annotation\\nallergies_df = allergies_df.rename(columns=lambda x: f\"allergies_{x}\" if x != \"PATIENT\" else x)\\ncareplans_df = careplans_df.rename(columns=lambda x: f\"careplans_{x}\" if x != \"PATIENT\" else x)\\nconditions_df = conditions_df.rename(columns=lambda x: f\"conditions_{x}\" if x != \"PATIENT\" else x)\\nimmunizations_df = immunizations_df.rename(columns=lambda x: f\"immunizations_{x}\" if x != \"PATIENT\" else x)\\nmedications_df = medications_df.rename(columns=lambda x: f\"medications_{x}\" if x != \"PATIENT\" else x)\\nobservations_df = observations_df.rename(columns=lambda x: f\"observations_{x}\" if x != \"PATIENT\" else x)\\n\\n# Merge datasets using Dask\\nmerged_df = dd.merge(allergies_df, careplans_df, on=\"PATIENT\", how=\"outer\")\\nmerged_df = dd.merge(merged_df, conditions_df, on=\"PATIENT\", how=\"outer\")\\nmerged_df = dd.merge(merged_df, immunizations_df, on=\"PATIENT\", how=\"outer\")\\nmerged_df = dd.merge(merged_df, medications_df, on=\"PATIENT\", how=\"outer\")\\nmerged_df = dd.merge(merged_df, observations_df, on=\"PATIENT\", how=\"outer\")\\n\\n# Compute the result to load into memory (you can persist or save it if needed)\\nmerged_df_computed = merged_df.compute()\\n\\n# Display the first few rows of the computed dataframe to the user\\nmerged_df_computed.head()\\n '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Rename columns with Dask for proper annotation\n",
    "allergies_df = allergies_df.rename(columns=lambda x: f\"allergies_{x}\" if x != \"PATIENT\" else x)\n",
    "careplans_df = careplans_df.rename(columns=lambda x: f\"careplans_{x}\" if x != \"PATIENT\" else x)\n",
    "conditions_df = conditions_df.rename(columns=lambda x: f\"conditions_{x}\" if x != \"PATIENT\" else x)\n",
    "immunizations_df = immunizations_df.rename(columns=lambda x: f\"immunizations_{x}\" if x != \"PATIENT\" else x)\n",
    "medications_df = medications_df.rename(columns=lambda x: f\"medications_{x}\" if x != \"PATIENT\" else x)\n",
    "observations_df = observations_df.rename(columns=lambda x: f\"observations_{x}\" if x != \"PATIENT\" else x)\n",
    "\n",
    "# Merge datasets using Dask\n",
    "merged_df = dd.merge(allergies_df, careplans_df, on=\"PATIENT\", how=\"outer\")\n",
    "merged_df = dd.merge(merged_df, conditions_df, on=\"PATIENT\", how=\"outer\")\n",
    "merged_df = dd.merge(merged_df, immunizations_df, on=\"PATIENT\", how=\"outer\")\n",
    "merged_df = dd.merge(merged_df, medications_df, on=\"PATIENT\", how=\"outer\")\n",
    "merged_df = dd.merge(merged_df, observations_df, on=\"PATIENT\", how=\"outer\")\n",
    "\n",
    "# Compute the result to load into memory (you can persist or save it if needed)\n",
    "merged_df_computed = merged_df.compute()\n",
    "\n",
    "# Display the first few rows of the computed dataframe to the user\n",
    "merged_df_computed.head()\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" output_path = 'merged_patient_data.h5'  # Update this path as needed\n",
    "\n",
    "# Load the HDF5 file into a Pandas DataFrame\n",
    "df = pd.read_hdf(output_path, key='df')\n",
    "\n",
    "# View the first few rows of the DataFrame\n",
    "csv_output_path = 'merged_patient_data.csv'  # Update this path as needed\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "df.to_csv(csv_output_path, index=False)\n",
    " \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
